---
category: technical-focus
certifications:
- information-management
difficulty: advanced
id: cnn-001
importance: 5
keywords:
- CNN
- Convolution
- Pooling
- ResNet
- ImageNet
- Computer Vision
relatedTopics:
- ai-deep-learning-001
- gradient-descent-001
subcategory: 알고리즘
subjectCategories:
- AL
- DS
tags:
- '2025'
title: CNN (Convolutional Neural Network)
trends:
- Vision Transformer (ViT)
- Efficient CNN (MobileNet, EfficientNet)
---

# 정의
이미지 데이터의 공간적 특징을 학습하기 위한 합성곱 신경망 기반 컴퓨터 비전 핵심 모델 기술.

## 특징
- Convolution Layer: 필터(커널)로 특징 추출, 가중치 공유, 지역적 연결
- Pooling Layer: 다운샘플링, Max Pooling, Average Pooling, 차원 축소
- Fully Connected Layer: 분류를 위한 완전 연결층
- Activation Function: ReLU, Leaky ReLU, 비선형성 추가
- 대표 아키텍처: LeNet (1998), AlexNet (2012), VGG (2014), ResNet (2015), Inception
- ResNet: Skip Connection (잔차 연결), 깊은 네트워크 학습 가능
- Data Augmentation: 회전, 반전, 크롭으로 데이터 증강
- Transfer Learning: 사전 학습 모델 (ImageNet) 활용
- 활용: 이미지 분류, 객체 탐지 (YOLO, R-CNN), 세그멘테이션

## 동작원리

CNN은 이미지의 공간적 구조를 보존하면서 특징을 추출하는 계층적 구조로 동작합니다:

**1. Convolution Layer (합성곱 계층)**
- 필터(커널) 슬라이딩: 3×3, 5×5 크기의 가중치 행렬을 이미지 위에서 이동
- Convolution 연산: output[i][j] = Σ Σ input[i+m][j+n] × filter[m][n]
- 가중치 공유 (Weight Sharing): 동일 필터를 전체 이미지에 적용, 파라미터 수 감소
- Feature Map 생성: 각 필터가 특정 패턴(edge, corner, texture) 감지
- 계층적 특징 추출: 얕은 층(low-level), 깊은 층(high-level) 특징

**2. Activation Function**
- ReLU(x) = max(0, x): 비선형성 추가
- Vanishing Gradient 문제 완화
- 음수 값 제거로 희소성 (Sparsity) 확보

**3. Pooling Layer**
- Max Pooling: 2×2 윈도우 내 최대값 선택
- 효과: 차원 축소, 작은 변형에 강건, 계산량 감소
- 위치 정보보다 특징 존재 여부 중시

**4. Forward Propagation 흐름**
```
Input (32×32×3) → Conv+ReLU → Pooling → Conv+ReLU → Pooling → Flatten → FC → Softmax (분류)
```

**5. ResNet Skip Connection**
- Residual Block: H(x) = F(x) + x
- Skip Connection으로 Gradient 직접 전달
- Vanishing Gradient 해결, 깊은 네트워크 (100+ 층) 학습 가능

**6. 역전파 학습**
- Forward: 예측값 계산
- Loss: Cross-Entropy Loss
- Backward: 기울기 역전파 (Pooling: Max 위치로만 전달, Conv: 필터 업데이트)
- Optimizer: SGD, Adam으로 가중치 갱신

## 최신 트렌드
- Vision Transformer (ViT)
- Efficient CNN (MobileNet, EfficientNet)