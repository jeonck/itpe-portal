---
category: digital-service
certifications:
- computer-systems
difficulty: advanced
id: hbm-001
importance: 5
keywords:
- HBM
- 고대역폭 메모리
- AI 가속기
- GPU
- TSV
relatedTopics:
- cache-memory-001
- ai-semiconductor-001
subcategory: 고성능 메모리
subjectCategories:
- CA
- DS
title: HBM (High Bandwidth Memory)
trends:
- HBM3, HBM3E
- PIM(Processing-in-Memory) 통합
- AI 서버 핵심 부품
---

# 정의
HBM(High Bandwidth Memory)은 여러 개의 DRAM 칩을 수직으로 쌓아 올려(3D 스태킹) 데이터 전송 대역폭을 획기적으로 향상시킨 고성능 메모리 기술입니다. AI 반도체(GPU, NPU 등)와 같은 고성능 프로세서 옆에 통합되어, AI 모델 학습 및 추론 시 발생하는 병렬 연산에 필요한 대량의 데이터를 매우 빠르게 공급하여 전체 시스템 성능을 극대화하는 데 필수적인 역할을 합니다.

## 기술요소
HBM의 핵심 기술 요소는 다음과 같습니다:

TSV (Through-Silicon Via) 기술
- 실리콘 칩을 관통하는 수직 연결 구조
- 직경 5~10μm의 미세한 구멍을 뚫고 도전성 물질(구리) 충전
- DRAM 칩들을 3D로 적층하여 수직 연결
- 와이어 본딩 대비 신호 경로 단축 (mm → μm)
- 전기적 저항 감소, 신호 지연 최소화

마이크로범프 (Microbump) 인터페이스
- HBM 스택과 GPU/CPU 칩 연결
- 수천 개의 초미세 범프로 병렬 연결 (HBM2: 1024-bit 인터페이스)
- PCB 기판 대신 Interposer(중간 기판) 사용
- 짧은 물리적 거리로 고대역폭 구현

채널 병렬화 구조
- 독립적인 메모리 채널 (HBM2: 8채널, HBM3: 16채널)
- 각 채널이 동시에 데이터 전송
- 채널당 128-bit 인터페이스
- 총 대역폭 = 채널 수 × 채널 대역폭

## 특징
- 고대역폭:
    - 기존 DDR 계열 DRAM 대비 수십 배 높은 데이터 전송 대역폭을 제공합니다. 이는 AI 모델의 방대한 파라미터와 데이터 처리에 필수적입니다.
    - TSV (Through-Silicon Via) 기술을 활용하여 DRAM 칩들을 수직으로 연결, 데이터 경로를 단축하고 전기적 저항을 줄입니다.
- 저전력:
    - 더 짧아진 데이터 경로 덕분에 기존 DRAM 대비 전력 효율이 우수합니다.
    - 고성능 연산 시 발생하는 발열 문제를 완화하는 데 기여합니다.
- 소형화:
    - 3D 스태킹 기술을 통해 좁은 면적에 더 많은 용량을 집적할 수 있어, AI 가속기 패키지 내에서 메모리 풋프린트를 줄입니다.
- 구조:
    - 베이스 다이 (Base Die): 메모리 컨트롤러 역할을 하며, 프로세서와 통신 인터페이스를 담당.
    - 코어 다이 (Core Die): 실제 데이터를 저장하는 DRAM 칩들. 여러 층으로 쌓여 베이스 다이와 TSV로 연결.
- 주요 적용 분야:
    - AI 가속기: GPU(NVIDIA H100, A100), NPU, TPU 등 AI 모델 학습 및 추론용 가속기.
    - 고성능 컴퓨팅 (HPC): 슈퍼컴퓨터, 서버.
    - 네트워크 장비: 고속 데이터 처리가 필요한 라우터, 스위치.
- 진화: HBM2, HBM2E, HBM3, HBM3E 등 지속적으로 성능이 개선되고 있으며, 용량과 대역폭이 증대되고 있습니다.
- PIM (Processing-in-Memory)과의 연계: HBM 내부에 연산 기능을 통합하는 PIM 기술과의 결합을 통해 데이터 이동 병목 현상을 더욱 줄이려는 시도가 진행 중입니다.