---
id: llm-001
title: LLM (거대언어모델)
category: digital-service
subcategory: AI/ML
subjectCategories:
  - DS
difficulty: advanced
certifications:
  - information-management
  - computer-systems
keywords:
  - Transformer
  - GPT
  - BERT
  - 프롬프트 엔지니어링
  - RAG
importance: 5
relatedTopics:
  - ai-deep-learning-001
  - rag-001
  - prompt-engineering-001
trends:
  - RAG (검색증강생성)
  - 멀티모달 LLM
  - LLMOps
  - 에이전트 AI
---

# 정의
수백억~수조 개의 파라미터로 구성된 거대 언어 모델로, Transformer 아키텍처 기반의 자연어 처리 AI입니다.

## 특징
- Transformer 아키텍처: Self-Attention 메커니즘으로 문맥 이해, Encoder-Decoder 또는 Decoder-only 구조
- 대표 모델: GPT(생성), BERT(이해), T5(통합). GPT-4는 1.7조 파라미터 추정
- Few-shot/Zero-shot Learning: 적은 예시 또는 예시 없이도 새로운 태스크 수행
- Prompt Engineering: 입력 프롬프트 설계로 모델 출력 제어. Chain-of-Thought, In-Context Learning
- RAG(Retrieval-Augmented Generation): 외부 지식 검색 후 생성하여 환각(Hallucination) 감소
