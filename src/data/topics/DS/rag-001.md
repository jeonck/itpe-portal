---
category: digital-service
certifications:
- information-management
difficulty: advanced
id: rag-001
importance: 5
keywords:
- RAG
- Retrieval
- Vector DB
- Embedding
- LLM
relatedTopics:
- llm-001
- nosql-001
subcategory: AI/ML
subjectCategories:
- DS
title: RAG (검색증강생성)
trends:
- GraphRAG
- Agentic RAG
- Multimodal RAG
- Self-RAG
---

# 정의
외부 지식 베이스에서 관련 정보를 검색(Retrieval)한 후 LLM으로 답변을 생성(Generation)하여, 정확성과 최신성을 향상시키는 AI 기법.


## 특징
- 동작 과정: 1) 질문 임베딩(벡터 변환) → 2) Vector DB에서 유사 문서 검색 → 3) 검색 결과를 컨텍스트로 LLM에 전달 → 4) 답변 생성
- 핵심 구성요소: Embedding 모델(텍스트→벡터, BERT, Sentence Transformers), Vector DB(Pinecone, Weaviate, FAISS), LLM(GPT, Claude)
- 장점: 환각(Hallucination) 감소, 최신 정보 반영(재학습 불필요), 출처 명시 가능, 도메인 특화 지식 활용

## 기술요소
RAG(검색증강생성) 시스템은 크게 검색(Retrieval) 모듈과 생성(Generation) 모듈로 구성되며, 이들을 연결하는 다양한 기술 요소들이 결합되어 작동합니다.

-   **질의 인코딩 (Query Encoding)**:
    -   **임베딩 모델 (Embedding Model)**:
        -   **정의**: 사용자 질의(쿼리)를 벡터 공간의 숫자 표현(임베딩 벡터)으로 변환하는 딥러닝 모델. 의미론적으로 유사한 질의는 가까운 벡터 공간에 위치하게 됩니다.
        -   **기술**: BERT, Sentence Transformers, Word2Vec, LLM의 임베딩 레이어 등.
        -   **역할**: 벡터 데이터베이스에서 관련 문서를 효율적으로 검색하기 위한 준비 단계.

-   **검색 (Retrieval) 모듈**:
    -   **벡터 데이터베이스 (Vector Database, Vector DB)**:
        -   **정의**: 텍스트, 이미지, 오디오 등 비정형 데이터를 임베딩 벡터 형태로 저장하고, 벡터 유사도 검색을 통해 관련성 높은 데이터를 빠르게 찾아내는 특화된 데이터베이스.
        -   **기술**: Approximate Nearest Neighbor (ANN) 알고리즘을 사용하여 대규모 벡터 데이터에서 유사한 벡터를 효율적으로 검색. (예: Pinecone, Weaviate, FAISS, Milvus).
        -   **역할**: 사용자 질의와 가장 유사한 의미를 가진 문서를 신속하게 찾아 LLM에 제공.
    -   **청크 분할 (Chunking)**:
        -   **정의**: 방대한 원본 문서를 LLM의 컨텍스트 윈도우 크기에 맞춰 의미 있는 작은 단위(청크)로 분할하는 과정.
        -   **기술**: 고정 크기 분할, 재귀적 분할, 의미 기반 분할 등.
        -   **역할**: LLM이 처리할 수 있는 입력 길이를 초과하지 않으면서도 핵심 정보를 포함한 문맥을 제공.
    -   **검색 전략**:
        -   **의미 검색 (Semantic Search)**: 임베딩 벡터 간의 유사도를 기반으로 질의의 의미와 관련된 문서를 검색.
        -   **키워드 검색 (Keyword Search)**: 전통적인 검색 엔진처럼 키워드 일치 여부를 기반으로 문서를 검색. (예: BM25)
        -   **하이브리드 검색 (Hybrid Search)**: 의미 검색과 키워드 검색을 조합하여 검색 정확도를 높입니다.
        -   **재순위화 (Re-ranking)**: 검색된 문서들의 순위를 LLM을 활용하여 다시 매겨 가장 관련성 높은 문서를 상위로 배치.

-   **생성 (Generation) 모듈**:
    -   **LLM (Large Language Model)**:
        -   **정의**: 검색 모듈에서 얻은 관련 문서를 '컨텍스트'로 활용하여 사용자 질의에 대한 답변을 생성하는 거대 언어 모델.
        -   **기술**: GPT, Claude, Llama 등.
        -   **역할**: 제공된 컨텍스트 내에서 질문에 대한 정확하고 유용한 답변을 자연어로 생성.

-   **파이프라인 관리**:
    -   **오케스트레이션 프레임워크**: LangChain, LlamaIndex와 같은 프레임워크는 RAG 파이프라인의 각 단계(임베딩, 검색, 생성)를 연결하고 관리하는 역할을 합니다.

이러한 기술 요소들이 결합하여 RAG 시스템은 LLM의 환각(Hallucination) 문제를 줄이고, 최신 정보 및 도메인 특화 지식을 활용하여 더욱 정확하고 신뢰할 수 있는 답변을 생성할 수 있도록 합니다.