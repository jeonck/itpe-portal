{
  "id": "ai-semiconductor-001",
  "title": "AI 반도체 (NPU, TPU, FPGA, ASIC)",
  "category": "digital-service",
  "subcategory": "AI 가속기",
  "subjectCategories": [
    "CA",
    "DS"
  ],
  "difficulty": "advanced",
  "certifications": [
    "computer-systems"
  ],
  "keywords": [
    "AI 반도체",
    "NPU",
    "TPU",
    "FPGA",
    "ASIC",
    "AI 가속기"
  ],
  "definition": "AI 반도체는 인공지능(AI) 연산에 특화되어 고성능, 저전력, 병렬 처리를 효율적으로 수행하도록 설계된 반도체입니다. CPU나 GPU와 같은 범용 프로세서의 한계를 극복하고 AI 모델의 학습 및 추론 속도를 가속화하여 AI 기술의 발전과 상용화를 이끄는 핵심 하드웨어 기술. NPU, TPU, FPGA, ASIC 등이 대표적인 AI 반도체 유형.",
  "operatingPrinciple": "AI 반도체는 다음과 같은 방식으로 AI 연산을 가속화합니다:\n\n행렬 연산 가속 (Matrix Multiplication Acceleration)\n- AI 모델의 핵심 연산인 행렬 곱셈을 전용 하드웨어로 처리\n- Systolic Array: 2D 배열 형태의 PE(Processing Element)로 구성\n- 각 PE가 곱셈-덧셈(MAC, Multiply-Accumulate) 연산 수행\n- 데이터가 배열을 통해 흐르며 병렬 처리\n\nTPU의 Systolic Array 동작\n1) 가중치(Weight)를 각 PE에 미리 로드\n2) 입력 데이터가 위에서 아래로 흐름\n3) 부분 합(Partial Sum)이 왼쪽에서 오른쪽으로 전파\n4) 최종 결과가 오른쪽 끝에서 출력\n\n데이터 재사용 (Data Reuse)\n- 온칩 메모리(SRAM)에 데이터 캐싱\n- 외부 메모리 접근 최소화 (전력 소비 감소)\n- Weight Stationary, Output Stationary 등 최적화 기법\n\n저정밀도 연산 (Low-Precision Computing)\n- FP32 대신 INT8, FP16, BF16 사용\n- 정밀도는 낮지만 추론 성능은 유지\n- 하드웨어 비용 및 전력 소비 대폭 감소",
  "characteristics": [
    "목표: AI 모델 학습(Training) 및 추론(Inference)의 효율성 극대화 (속도, 전력 효율).",
    "NPU (Neural Processing Unit):"
  ],
  "relatedTopics": [
    "gpu-architecture-001",
    "ai-deep-learning-001"
  ],
  "importance": 5,
  "trends": [
    "온디바이스 AI 칩",
    "저전력 AI 반도체",
    "시스템 반도체 경쟁 심화"
  ]
}